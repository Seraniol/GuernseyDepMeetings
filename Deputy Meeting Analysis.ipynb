{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guernsey Deputy Meetings - Hansard Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A learning exercise with the aim of using text mining in Python as exploratory data analysis to identify patterns in Deputy meetings and provide a comprehensive source of information of the opinions expressed by deputies*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Intro\n",
    "I've chosen to persue this as the steps involved require a mix of disciplines, all of which should help expand my skills in both practical performance of analytics as well as code management\n",
    "\n",
    "**Storage and Management**  \n",
    "SharePoint will be used to store files but they will be primarily managed in a GitHub repository\n",
    "\n",
    "**Presentation**  \n",
    "Jupyter Notebooks will be used in order to document any decisions made and the process undertaken to analyse or manipulate data\n",
    "\n",
    "**Data Collection**  \n",
    "Most initial data will be imported manually at this stage, but web scraping might be investigated as a later exercise\n",
    "\n",
    "**Data Transformation and Analysis**  \n",
    "Initial data transformation and analysis will be performed in Python. Some presentation may be done in Power BI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of options for collecting data on discussions held during States meetings, the main ones considered for identifying opinions expressed by Deputies are:\n",
    "\n",
    "1. The audio from recordings available through Microsoft Teams\n",
    "2. A summary Excel or PDF log (used in Meeting Analysis.pbix to identify time spent speaking by each Deputy)\n",
    "3. A verbatim official PDF report of proceedings, named a 'Hansard'\n",
    "\n",
    "The quality of the audio recordings varies wildly and, while interesting to look at in future, is unlikely to produce results due to issues in the audio quality.  \n",
    "The Excel logs are useful for determining the length of time spent speaking, but lacks sufficient detail to offer further meaningful analysis.  \n",
    "Therefore, the Hansard reports have been selected for analysis. \n",
    "\n",
    "Only final Hansard reports will be used and will be collected manually from each meeting page which can be accessed through the [States meeting information index](https://www.gov.gg/article/163276/States-Meeting-information-index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PDFs\n",
    "Import Hansard files and use PDF Miner to begin exploring text.  \n",
    "Before analysis the aim is to convert this intro a structured format where each record is either a sentence or contiguous speech from one deputy, with variables showing at least the date of the meeting, the speaker and the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LTPage(1) 0.000,0.000,595.320,841.920 rotate=0>\n",
      "<LTTextBoxHorizontal(0) 72.024,756.720,93.719,767.760 'Test \\n'>\n",
      "<LTTextBoxHorizontal(1) 72.024,734.260,74.519,745.300 ' \\n'>\n",
      "<LTTextBoxHorizontal(2) 72.024,711.700,93.359,722.740 'Test \\n'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage, PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine, LTChar\n",
    "\n",
    "def extract_char_from_text(layout):\n",
    "    text = \"\"\n",
    "    print(layout)\n",
    "    for lt_obj in layout:\n",
    "        print(lt_obj)\n",
    "#         if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj,LTTextLine):\n",
    "#             # Recursion until down to LTChar\n",
    "#             extract_char_from_text(lt_obj)\n",
    "#         elif isinstance(lt_obj, LTChar):\n",
    "#             # If at LTChar in tree, get result\n",
    "#             text = lt_obj._text\n",
    "#             print(text)\n",
    "#         return text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    # Open a PDF file.\n",
    "    fp = open(pdf_path, 'rb')\n",
    "    # Create a PDF parser object associated with the file object.\n",
    "    parser = PDFParser(fp)\n",
    "    # Create a PDF document object that stores the document structure.\n",
    "    document = PDFDocument(parser)\n",
    "    # Check if the document allows text extraction. If not, abort.\n",
    "    if not document.is_extractable:\n",
    "        raise PDFTextExtractionNotAllowed\n",
    "    # Create a PDF resource manager object that stores shared resources.\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    # Set parameters for analysis.\n",
    "    laparams = LAParams()\n",
    "    # Create a PDF device object.\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams = laparams)\n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    # Create a string output object\n",
    "    strout = io.StringIO()\n",
    "    # Process each page contained in the document.\n",
    "    for page in PDFPage.create_pages(document):\n",
    "        interpreter.process_page(page)\n",
    "        layout = device.get_result()\n",
    "\n",
    "        text = extract_char_from_text(layout)\n",
    "        print(text)\n",
    "   \n",
    "\n",
    "#         for lt_obj in layout:\n",
    "\n",
    "#             if hasattr(lt_obj, \"get_text\"):\n",
    "#                 text = lt_obj.get_text()\n",
    "#                 strout.write (text)\n",
    "\n",
    "#     text = strout.getvalue()\n",
    "#     strout.close()\n",
    "#     return text\n",
    "\n",
    "##See https://stackoverflow.com/questions/25248140/how-does-one-obtain-the-location-of-text-in-a-pdf-with-pdfminer for help on recursively exploring the tree in order to find font info\n",
    "\n",
    "\n",
    "extract_text_from_pdf('Hansard/Test.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
